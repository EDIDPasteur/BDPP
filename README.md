# Bacterial genomes Download and Processing Pipeline

[![Snakemake](https://img.shields.io/badge/Snakemake-â‰¥9.6.0-brightgreen.svg?style=flat)](https://snakemake.readthedocs.io)
[![License (AGPL version 3)](https://img.shields.io/badge/license-GNU%20AGPL%20version%203-green.svg)](COPYING)
[![pipeline status](https://gitlab.pasteur.fr/jsevilla/bdpp/badges/dev/pipeline.svg)](https://gitlab.pasteur.fr/jsevilla/bdpp/-/commits/dev)

The porpouse of this pipeline is to download and process bacterial sequencing reads from the SRA database.

---

## Installation

You have the option to download the zipped version of this repository (find the button on the right-hand side of the screen). Also it is possible to clone this repository:

```
git clone git@gitlab.pasteur.fr:jsevilla/bdpp.git
cd bdpp

```

In case your system lacks Snakemake version > 9.6.0, it is necessary to [download and install it](https://snakemake.readthedocs.io/en/stable/getting_started/installation.html).

If ypu have a conda distribution installed, you can use it to install snakemake as follows:

```
conda create -n snakemake -c conda-forge -c bioconda snakemake=9.6.0

conda activate snakemake
```

## Usage

To run the pipeline, you need to fill the [targets file](config/target.yaml) with the information of the samples you want to process. The file should contain the following fields:
- ACCESSION_FILE: Path to a file containing the SRA accessions of the samples you want to process. One accession per line.
- OUTDIR: Path to the output directory where the processed data will be stored.
- PREFIX: Prefix to be used for the output files. This is useful to distinguish between different runs of the pipeline.
- REFERENCE: Accession of the reference genome to be used for the mapping step. This should be a valid accession from the NCBI database. (NC_011035.1 for example)

You can also modify the [config file](config/config.yaml) to change the default parameters of the pipeline, such as the number of threads to use for each step, the quality control tools to use, etc.

Then you can run the pipeline with the following command:

```
snakemake --use-conda --cores [number_of_cores]
```

In addition, you can also run the pipeline with the [bdpp-runner.py](bdpp-runner.py) script which has the following options:

```
usage: bdpp-runner.py [-h] [-c CORES] -a ACCESSIONS [-o OUTDIR] [-p PREFIX] -r REFERENCE

Run the BDPP snakemake workflow.

options:
  -h, --help            show this help message and exit
  -c CORES, --cores CORES
                        Number of cores to use for the workflow
  -a ACCESSIONS, --accessions ACCESSIONS
                        File containing the accessions to process (one per line)
  -o OUTDIR, --outdir OUTDIR
                        Output directory for the results
  -p PREFIX, --prefix PREFIX
                        Prefix for the output files
  -r REFERENCE, --reference REFERENCE
                        Accession of the reference genome to be used for the mapping step. This should be a valid accession from the NCBI
                        database. (NC_011035.1 for example)
```
This script manage correctly paths within your system so you can add the [bdpp-runner.py](bdpp-runner.py) script to your PATH and use it in any location.


## Outputs

The pipeline will generate the following main outputs in the output directory specified in the targets file:
- Raw fastq files: The raw fastq files downloaded from the SRA database.
- Cleaned fastq files: The cleaned fastq files after quality control and trimming.
- Quality control reports: The quality control reports generated by FastQC and MultiQC before and after cleaning the reads.
- Mapping results: The mapping results generated by Snippy, including the reference mapping alignment.
- Assembly results: The assembly results generated by SPAdes, including the assembly and the statistics report.

## Pipeline steps

The pipeline consists of the following steps and analyses

### Downloading the SRA files

The pipeline will download the SRA files from the NCBI database using the accessions provided in the targets file. It will use the [`enaBrowserTools`](https://github.com/enasequence/enaBrowserTools).

### Quality control

The pipeline will perform quality control on the downloaded fastq files using [`FastQC`](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) and [`MultiQC`](https://seqera.io/multiqc/). It will generate a report with the quality metrics of the samples before cleaning them.

### Cleaning the reads

The pipeline will clean the reads using [`Fastp`](https://github.com/OpenGene/fastp). This tool allows to automatically trim adapters without an adapters file. Moreover, reads are trimmed nd filtered based on base quality and length using the parameters defined in the config file. Then, a new report will be generated with the quality metrics of the cleaned reads.

### Mapping the reads

The pipeline will map the cleaned reads to the reference genome using [`snippy`](https://github.com/tseemann/snippy) and combine the results with `snippy-core` to generate a reference mapping alignment. The mapping will be performed using the parameters defined in the config file. Then, [`ClipKIT`](https://github.com/JLSteenwyk/ClipKIT) is used to remove the low quality regions from the mapping.

### Assembly

The pipeline will assemble the cleaned reads using the [`shovill`](https://github.com/tseemann/shovill) pipeline. The spades parameters can be modified in the config file. An in house python script ([assembly_stats.py](scripts/assembly_stats.py)) will be used to generate a report with the assembly statistics (genome length, number of contigs, n50 and number of ambiguous bases).


## Considerations

- The pipeline assumes paired-end reads.
- The pipeline use conda environments to run the tools, so it is necessary to have conda installed in your system and some problems may arise in diferent systems.

## Contributing

If you want to contribute to this project please follow these steps:
1. Clone the repository
2. navegate to the dev branch:
   ```
   git checkout dev
   ```
3. Create a new branch for your changes (dev-$your_name)
   ```
   git checkout -b dev-$your_name
   ```
4. Make your changes and commit them
5. Push your changes to the remote repository
   ```
   git push origin dev-$your_name
   ```
6. Create a merge request to the dev branch
7. Wait for the review and merge your changes

Onece substancial changes are made, the dev branch will be merged into the main branch and a new release will be created.

